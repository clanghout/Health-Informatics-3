\chapter{Interaction Design} %MAX 2 PAGES
In this chapter we will describe the interaction design test we have done with the user. First we will describe the persona of a typical user of the tool and next we will tell how the test. Furthermore we will draw the conclusions from the test.

\section{Methods}
We put the user behind the computer and asked him to perform tasks. We first wanted him to read in files and then perform analyses. If the user can not figure out how to do something, we gave some hints to help him along the way. The more complicated analyses were pre-written so that the user only has to modify the existing analysis to make it work. We did this because the language we use has a high learning curve and we did not have a lot of time at the test to make the user learn the complete language.

\section{Expectation}
In this section we will describe what we expected how the test would go. We expected that the test could be a bit too difficult. This is because the the language we use is not that easy to understand at the first time using it. We provided the users with some example scripts of the language to make this process easier.
We expected that the graphical user interface would be easier to understand.

\section{General Persona}
In this section we will describe John Doe who is an abstraction of our typical user.\\
John is an analyst and he uses analysis tools on a regular basis. His analyses are performed on data that is collected during research. He has a specific goal in mind and he wants to get to an answer to a specific question about the data. John also has minimal experience in programming, but is familiar with scripts from other analysis tools and is eager to learn a new scripting language.

\section{Evaluations}
Every Friday the team had a meeting with the client to show progress and get feedback on the demo. To show our progress to the client we used the high fidelity prototyping principle.
\subsection{Usability evaluation}
To test the usability and functionality of the program, tests are done with our client Miss Wang. A meeting was arranged where the program was used by the client and the functionalities of the program were shown. For the example questions that the client wants to answer pre-made scripts were executed and feedback was given on the overall process.\\
Little things were changed as a result of the meeting, for example the save button was moved because right below the import button did not make sense. We also discovered during this meeting that the visualizations did not work anymore due to changes in parts the visualizations are dependant on. Overall the client was positive about the product since most of the analyses could be executed.
\subsection{Additional test results}
Other tests were done with fellow students. The detailed results are found in appendix \ref{ch:results}.\\
Generally the tests resulted that our language is quite difficult to understand, which was already predicted. The user interface was generally clear and only little remarks were made on positioning of buttons. With the provided examples of analysis scripts the testers could reproduce a similar analysis with reasonable effort. Most of the time it was clear which part of the interface belonged to which feature with little exception in the visualization selection. The general impression of the program was good, the interface is clear analysis functionality is good.